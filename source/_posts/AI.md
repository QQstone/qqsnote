---
title: AI science
date: 2023-08-31 10:39:46
tags:
---
[提示工程](https://www.promptingguide.ai/zh)


LangGraph
专注于构建具有记忆和上下文的多步对话智能代理，支持循环数据流处理，解决了传统聊天系统无法获取实时信息的问题。其设计哲学强调动态工作流管理，适合需要复杂决策链的应用（如多轮交互客服）。
LangChain
作为基础框架，提供模块化组件（如模型封装、提示模板、向量数据库集成），快速搭建 LLM 应用原型。但缺乏对长期对话状态的支持，需结合其他工具增强功能。
LangSmith
是DevOps 平台，专注于 LLM 应用的调试、测试和部署监控。支持追踪链路执行、分析性能瓶颈，适合生产环境优化。

MCP全称：模型上下文协议 ，Model Context Protocol，由Claude的母公司Anthropic推出的开源协议，旨在实现大型语言模型（LLM）与外部数据源和工具的集成，提供安全双向的连接。MCP通过统一的接口标准化了应用程序向LLM提供上下文的方式。

MCP的核心定位是为大型语言模型（LLM）与外部数据源、工具之间提供统一接口，实现标准化连接。其设计理念类似于“AI领域的USB-C接口”，通过协议标准化，打破数据孤岛，避免为每个数据源单独开发定制化连接器，从而降低开发成本和安全风险。

核心功能
作为 AI 大模型的标准化工具箱，允许大模型通过标准化协议与外部工具（如浏览器、文件系统、数据库、代码仓库等）自动化交互，无需手动复制粘贴信息。

MCP Server：作为 AI 与外部工具的中间层，专精于一类工作（如读写浏览器、操作 Git 仓库等），本质是运行在本地（Node.js/Python 程序）或服务器的程序。

交互方式：大模型通过操作系统的标准输入通道（stdio）调用 MCP Server，消息格式为特定 JSON 结构，MCP Server 通过代码或 API 访问外部工具完成任务。

MCP 与 Function Call 的区别
优势：整合了各家大模型不同的 Function Call 标准，形成统一协议，支持几乎所有大模型接入（如 Claude、Deepseek 等）。

MCP：是 Anthropic 提出的标准化通信协议，类比为 “AI 领域的 HTTP 协议” 或 “通用插座”“USB-C 标准”。它规定了上下文与请求的结构化传递方式，要求通信格式符合 JSON-RPC 2.0 标准，用于统一 LLM 与外部数据源、工具之间的交互规范，解决数据孤岛问题。

Function Call：是某些大模型（如 OpenAI 的 GPT-4）提供的特有接口特性，类似 “品牌专属充电协议”。它以特定格式让 LLM 产出函数调用请求，由宿主执行对应操作并返回结果。

Cline 是一款集成在 Visual Studio Code（以下简称 VS Code）中的开源 AI 编程助手